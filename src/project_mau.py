# -*- coding: utf-8 -*-
"""Project mau.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pHb2fVuR_QHh1Tb0f4DnaEytEpAm2SrL

## Import thư viện
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score
from joblib import dump, load

"""## Load Data

Advertising.csv thể hiện doanh số (đơn vị tính bằng nghìn) của một sản phẩm cụ thể tính theo ngân sách quảng cáo (đơn vị tính bằng nghìn đô la) trên các phương tiện truyền thông như TV, radio và newspaper.
"""

df = pd.read_csv("Advertising.csv")

df.head()

"""## Khám phá dữ liệu"""

df.shape

df.columns

df.info()

"""## Xử lý missing value và duplicated"""

df.isnull().sum()

#df.duplicated()
#df.duplicated().sum()
df.duplicated().values.any()

"""## Thống kê mô tả"""

df.describe()



"""## Khai phá dữ liệu/Trực quan đặc trưng

- Mối quan hệ giữa chi tiêu quảng cáo và doanh số

- Mối quan hệ giữa từng kênh quảng cáo (TV, Radio, Newspaper) và doanh số

- Dự đoán doanh số theo chi tiêu quảng cáo.

### Tương quan các biến Correlation matrix
"""

correlation_matrix = df.corr()
print(correlation_matrix)

sns.heatmap(correlation_matrix, annot=True)

"""### Biểu đồ phân tán"""

#Trên 3 biểu đồ
plt.scatter(df['TV'],df['sales'],marker='o')
slope, intercept = np.polyfit(df['TV'], df['sales'], 1)
#1: phương trình bậc 1
trendline = slope * df['TV'] + intercept
plt.plot(df['TV'], trendline, 'r')
plt.xlabel('TV Ad')
plt.ylabel('Sales')
plt.show()

plt.scatter(df['radio'],df['sales'],marker='o')
plt.xlabel('Radio Ad')
plt.ylabel('Sales')
plt.show()

plt.scatter(df['newspaper'],df['sales'],marker='o')
plt.xlabel('Newspaper Ad')
plt.ylabel('Sales')
plt.show()

#Subplot 3 biểu đồ/1 figure
fg, ax = plt.subplots(1, 3, figsize=(16, 6))
ax[0].scatter(df['TV'],df['sales'],marker='o')
ax[0].set_xlabel('TV Ad')
ax[0].set_ylabel('Sales')
ax[0].set_title("TV Ad vs Sale")

ax[1].scatter(df['radio'],df['sales'],marker='o')
ax[1].set_xlabel('Radio Ad')
ax[1].set_title("Radio Ad vs Sale")


ax[2].scatter(df['newspaper'],df['sales'],marker='o')
ax[2].set_xlabel('Newspaper Ad')
ax[2].set_title("Newspaper Ad vs Sale")

fg.suptitle('Biểu đồ phân tán', fontsize=18)
plt.tight_layout();

plt.subplots(1,3,figsize=(16,6))
plt.subplot(1,3,1)
plt.scatter(df['TV'],df['sales'],marker='o')
plt.xlabel('TV Ad')
plt.ylabel('Sales')
plt.title("TV Ad vs Sale")

plt.subplot(1,3,2)
plt.scatter(df['radio'],df['sales'],marker='o')
plt.xlabel('Radio Ad')
plt.title("Radio Ad vs Sale")

plt.subplot(1,3,3)
plt.scatter(df['newspaper'],df['sales'],marker='o')
plt.xlabel('Newspaper Ad')
plt.title("Newspaper Ad vs Sale")

plt.tight_layout()
plt.show()

"""
### Phân phối của từng biến"""

sns.displot(df['sales'],
            bins=20, #chia 20 khoảng
            aspect=2,
            kde=True,
            color='r')

plt.title('Biểu đồ phân bố Sales')
plt.xlabel('Sales')
plt.ylabel('Count')
plt.show()

sns.histplot(df['sales'],
            bins=20, #chia 20 khoảng
            kde=True,
            color='r')

plt.title('Biểu đồ phân bố Sales')
plt.xlabel('Sales')
plt.ylabel('Count')
plt.show()

df.describe()

sns.histplot(df['TV'],
            bins=50,
            kde=True,
            color='r')

plt.title('Biểu đồ phân bố TV Ad')
plt.xlabel('TV Ad')
plt.ylabel('Count')
plt.show()

sns.histplot(df['radio'],
            bins=50,
            kde=True,
            color='r')

plt.title('Biểu đồ phân bố Radio Ad')
plt.xlabel('Radio Ad')
plt.ylabel('Count')
plt.show()

sns.histplot(df['newspaper'],
            bins=50,
            kde=True,
            color='r')

plt.title('Biểu đồ phân bố Newspaper Ad')
plt.xlabel('Newspaper Ad')
plt.ylabel('Count')
plt.show()

sns.boxplot(data = df, y = df['newspaper'])

q1 = df['newspaper'].quantile(0.25)
q3 = df['newspaper'].quantile(0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr
outlier = df[(df['newspaper'] < lower_bound) | (df['newspaper'] > upper_bound)]
print(outlier)

"""- Phân bố của Sales có dạng phân bố chuẩn (Normal Distrubution), không có outlier thật sự nổi bật, không cần xử lý outlier

- Đối với Newspaper Ad

Khoảng IQR:

IQR=Q3−Q1=45.1−12.75=32.35

Giá trị dưới ngưỡng: Q1−1.5×IQR=12.75−1.5×32.35≈−41.425

Giá trị trên ngưỡng: Q3+1.5×IQR=45.1+1.5×32.35≈99.275

Phân bố của Newspaper Ad có 2 điểm outlier (100 và 114) có thể có ý nghĩa trong bối cảnh chi quảng cáo trên newpaper, không cần loại bỏ.

"""

# Biểu đồ cặp (pairplot) biểu diễn tương quan giữa các cột trong DataFrame df dùng hàm KDE(ước lượng mật độ xác suất)
# Đường chéo hiển thị phân phối của từng biến
sns.pairplot(df,diag_kind='kde')

"""## Huấn luyện"""

#Biến độc lập
x = df.drop('sales',axis=1)
#Biến phụ thuộc
y = df['sales']

"""## Chia tập Train | Test"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

x_train

y_train

x_test

y_test

"""## Tạo mô hình huấn luyện"""

help(LinearRegression)

model = LinearRegression()

model.fit(x_train,y_train)

"""### Đánh giá trên tập test"""

y_pred = model.predict(x_test)

y_pred

y_df = pd.DataFrame(y_pred, index=y_test.index)
y_table = pd.concat([y_test,y_df],axis=1)
y_table.columns = ['Y_Test','Y_Pred']
y_table

MAE = mean_absolute_error(y_test,y_pred)
MSE = mean_squared_error(y_test,y_pred)
# RMSE = np.sqrt(MSE)
RSQUARE1 = model.score(x_train,y_train)
RSQUARE2 = model.score(x_test,y_test)
RSQUARE3 = model.score(x,y)

#RSQUARE2 = model.score(x_test,y_test) TƯƠNG ĐƯƠNG
r2_1 = r2_score(y_test,y_pred)
print('MAE',MAE)
print('MSE',MSE)
# print(RMSE)
print(f'Rsquared 1: {RSQUARE1*100:.2f}')
print(f'Rsquared 2: {RSQUARE2*100:.2f}') #overfitting
print(f'Rsquared 2_1: {r2_1*100:.2f}')
print(f'Rsquared 3: {RSQUARE3*100:.2f}')

from mlxtend.evaluate import bias_variance_decomp
mse, bias, var = bias_variance_decomp(model, x_train.values, y_train.values, x_test.values, y_test.values, loss='mse', num_rounds=200, random_seed=1)
print(mse)
print(bias)
print(var)

#mse = bias + var

"""### Trực quan kết quả hồi quy theo 1 biến độc lập TV"""

# plt.scatter(x_test.iloc[:,0],y_test,s=40,color='green')
# plt.scatter(x_test.iloc[:,0],y_pred,s=40,color='red')
plt.scatter(x_test['TV'],y_test,s=40,color='green',label = 'Real')
plt.scatter(x_test['TV'],y_pred,s=40,color='red', label = 'Predict')

inc = model.intercept_
coef = model.coef_[0]

x_value = np.linspace(x_test['TV'].min(), x_test['TV'].max(), 100)

y_value = coef * x_value + inc
plt.plot(x_value, y_value, c='blue')
plt.legend()
plt.show()

"""### Trực quan kết quả hồi quy theo 3 biến độc lập"""

x0_value = np.linspace(x_test.iloc[:, 0].min(), x_test.iloc[:, 0].max(), 100)
x1_value = np.linspace(x_test.iloc[:, 1].min(), x_test.iloc[:, 1].max(), 100)
x2_value = np.linspace(x_test.iloc[:, 2].min(), x_test.iloc[:, 2].max(), 100)

inc = model.intercept_
coef0 = model.coef_[0]
coef1 = model.coef_[1]
coef2 = model.coef_[2]

X0, X1 = np.meshgrid(x0_value, x1_value)
Y = coef0 * X0 + coef1 * X1 + coef2 * np.mean(x2_value) + inc

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

# Vẽ mặt hồi quy
ax.plot_surface(X0, X1, Y, color='blue', alpha=0.5, label='Mặt hồi quy')

ax.scatter(x_test.iloc[:, 0], x_test.iloc[:, 1], y_test, color='green', label='Y_Test')
ax.scatter(x_test.iloc[:, 0], x_test.iloc[:, 1], y_pred, color='red', label='Y_Pred')
plt.legend()
plt.show()

"""### Trực quan kết quả hồi quy theo từng biến độc lập"""

fg,ax = plt.subplots(1, 3, figsize=(16,6))

ax[0].plot(x_test.iloc[:, 0],y_test,'o')
ax[0].plot(x_test.iloc[:, 0],y_pred,'o',color='red')
inc = model.intercept_
coef0 = model.coef_[0]
x_value = np.linspace(x_test.iloc[:, 0].min(), x_test.iloc[:, 0].max(), 100)
y_value = coef0 * x_value + inc
ax[0].plot(x_value, y_value, c='blue')
ax[0].set_ylabel("Sales")
ax[0].set_title("TV Ad")

ax[1].plot(x_test.iloc[:, 1],y_test,'o')
ax[1].plot(x_test.iloc[:, 1],y_pred,'o',color='red')
inc = model.intercept_
coef1 = model.coef_[1]
x1_value = np.linspace(x_test.iloc[:, 1].min(), x_test.iloc[:, 1].max(), 100)
y1_value = coef1 * x1_value + inc
ax[1].plot(x1_value, y1_value, c='blue')
ax[1].set_title("Radio Ad")
ax[1].set_ylabel("Sales")

ax[2].plot(x_test.iloc[:, 2],y_test,'o')
ax[2].plot(x_test.iloc[:, 2],y_pred,'o',color='red')
inc = model.intercept_
coef2 = model.coef_[2]
x2_value = np.linspace(x_test.iloc[:, 2].min(), x_test.iloc[:, 2].max(), 100)
y2_value = coef2 * x2_value + inc
ax[2].plot(x2_value, y2_value, c='blue')
ax[2].set_title("Newspaper Ad")
ax[2].set_ylabel("Sales")

fg.suptitle('HỒI QUY CÁC BIẾN', fontsize=18)
plt.tight_layout()

"""### Phân tích kết quả dự báo"""

coef_df = pd.DataFrame(model.coef_,x.columns,columns=['Coefficient'])
coef_df

model.intercept_

y = 0.04*x1+0.17*x2+0.0018*x3+intercept

"""Tăng 1 đơn vị (1k đô la) trong chi phí quảng cáo trên TV dẫn đến tăng doanh số bán hàng là 0,046 đơn vị. Điều này có nghĩa là với mỗi 1.000 đô la chi cho quảng cáo trên TV, dự báo sẽ bán thêm 46 đơn vị hàng hóa nữa.

Tăng 1 đơn vị (1k đô la) trong chi phí quảng cáo trên radiodẫn đến tăng doanh số bán hàng là 0,176 đơn vị. Điều này có nghĩa là với mỗi 1.000 đô la chi cho quảng cáo trên radio,dự báo sẽ bán thêm 176 đơn vị hàng hóa nữa.

Tăng 1 đơn vị (1k đô la) trong chi phí quảng cáo trên newspaperdẫn đến tăng doanh số bán hàng là 0,0018 đơn vị. Điều này có nghĩa là với mỗi 1.000 đô la chi cho quảng cáo trên newspaper, không thể bán thậm chí là được 1 đơn vị hàng hóa. Chi tiêu cho quảng cáo trên newspaper không có tác động thực sự đến doanh số bán hàng.

### Dự đoán trên dữ liệu mới

Dự báo doanh số cho chiến dịch quảng cáo có tổng chi phí là 149k cho quảng cáo trên TV, 22k cho quảng cáo trên Radio và 12k cho quảng cáo trên Newspaper.
"""

new_ad = [[149,22,12]]

model.predict(new_ad)

"""Dự báo sẽ bán được 27 đơn vị hàng hóa

## Lưu model
"""

dump(model, 'sales_model.joblib')

#Load lại model và test
loaded_model = load('sales_model.joblib')

loaded_model.predict(new_ad)

#Supervised learning
#Prediction
#Regression

#Linear regression
model = LinearRegression()
model.fit(x_train,y_train)
y_pred = model.predict(x_test)

MAE = mean_absolute_error(y_test,y_pred)
MSE = mean_squared_error(y_test,y_pred)
r2 = r2_score(y_test,y_pred)
print('MAE',MAE)
print('MSE',MSE)
print(f'Rsquared: {r2*100:.2f}')

#Ridge regression
from sklearn.linear_model import Ridge
model = Ridge(alpha=10) #alpha hệ số hiệu chỉnh, alpha càng mạnh hiệu chỉnh càng mạnh
model.fit(x_train,y_train)
y_pred = model.predict(x_test)

MAE = mean_absolute_error(y_test,y_pred)
MSE = mean_squared_error(y_test,y_pred)
r2 = r2_score(y_test,y_pred)
print('MAE',MAE)
print('MSE',MSE)
print(f'Rsquared: {r2*100:.2f}')

#GridSearchCV giúp tìm các bộ hệ số tối ưu cho các model học máy
from sklearn.model_selection import GridSearchCV
alphas = [0.001, 0.01, 0.1, 1, 10]

ridge_model = Ridge()
para = {'alpha':alphas}
grid = GridSearchCV(ridge_model, para, cv = 5, scoring = 'r2')
grid.fit(x_train, y_train)
print(grid.best_params_['alpha'])
print(grid.best_score_)

#Lasso regression
#giúp loại bỏ những biến không cần thiết, những biến có tương quan thấp
from sklearn.linear_model import Lasso
model = Lasso(alpha=1) #alpha càng lớn, càng loại bỏ nhiều biến không cần thiết
model.fit(x_train,y_train)
y_pred = model.predict(x_test)

MAE = mean_absolute_error(y_test,y_pred)
MSE = mean_squared_error(y_test,y_pred)
r2 = r2_score(y_test,y_pred)
print('MAE',MAE)
print('MSE',MSE)
print(f'Rsquared: {r2*100:.2f}')

#Decision tree
from sklearn.tree import DecisionTreeRegressor
model = DecisionTreeRegressor(max_depth=4)
model.fit(x_train,y_train)
y_pred = model.predict(x_test)

MAE = mean_absolute_error(y_test,y_pred)
MSE = mean_squared_error(y_test,y_pred)
r2 = r2_score(y_test,y_pred)
print('MAE',MAE)
print('MSE',MSE)
print(f'Rsquared: {r2*100:.2f}')

#Random forest
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(n_estimators=100, random_state=0)
model.fit(x_train,y_train)
y_pred = model.predict(x_test)

MAE = mean_absolute_error(y_test,y_pred)
MSE = mean_squared_error(y_test,y_pred)
r2 = r2_score(y_test,y_pred)
print('MAE',MAE)
print('MSE',MSE)
print(f'Rsquared: {r2*100:.2f}')

#XGBoost
from xgboost import XGBRegressor
model = XGBRegressor(n_estimators=200, learning_rate=0.08,random_state=0)
model.fit(x_train,y_train)
y_pred = model.predict(x_test)

MAE = mean_absolute_error(y_test,y_pred)
MSE = mean_squared_error(y_test,y_pred)
r2 = r2_score(y_test,y_pred)
print('MAE',MAE)
print('MSE',MSE)
print(f'Rsquared: {r2*100:.2f}')

"""- Dùng GridSearchCV xác định lại các bộ tham số tối uu cho các thuật toán trên
- Phân tích dự báo Charges cho dataset Insurance.csv theo các thuật toán vừa học

"""

#K nearest neighbor
from sklearn.neighbors import KNeighborsRegressor
model = KNeighborsRegressor(n_neighbors=5, weights='distance')
model.fit(x_train,y_train)
y_pred = model.predict(x_test)

MAE = mean_absolute_error(y_test,y_pred)
MSE = mean_squared_error(y_test,y_pred)
r2 = r2_score(y_test,y_pred)
print('MAE',MAE)
print('MSE',MSE)
print(f'Rsquared: {r2*100:.2f}')